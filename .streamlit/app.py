import re
import time
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import streamlit as st
import requests
import feedparser
from bs4 import BeautifulSoup

import plotly.graph_objects as go

import yfinance as yf
import FinanceDataReader as fdr
from pykrx import stock as krx
from pandas_datareader.data import DataReader


# -----------------------------
# Page
# -----------------------------
st.set_page_config(
    page_title="ì¬í…Œí¬ í•µì‹¬ì§€í‘œ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide"
)

st.title("ğŸ“Š ì¬í…Œí¬ í•µì‹¬ì§€í‘œ ëŒ€ì‹œë³´ë“œ")
st.caption("ì£¼ìš” ì§€ìˆ˜ Â· êµ­ë‚´ ì‹œì´ Top10 Â· í™˜ìœ¨ Â· ê¸ˆ/ìœ ê°€ Â· ê¸ˆë¦¬ Â· ì‹¤ì‹œê°„ ê²½ì œë‰´ìŠ¤(ë„¤ì´ë²„/ë‹¤ìŒ/êµ¬ê¸€) â€” ì¼ê°„/ì£¼ê°„/ì›”ê°„")


# -----------------------------
# Helpers
# -----------------------------
def _today_kst() -> datetime:
    # Streamlit Cloud timezone may vary; treat as local now for display
    return datetime.now()

def _days_for_freq(freq: str) -> int:
    # ê¸°ë³¸ ì¡°íšŒ ë²”ìœ„(íƒ­ë³„ë¡œ ë³´ê¸° í¸í•˜ê²Œ)
    if freq == "D":
        return 180
    if freq == "W":
        return 365 * 3
    if freq == "M":
        return 365 * 10
    return 365

def _to_freq_label(freq: str) -> str:
    return {"D": "ì¼ê°„", "W": "ì£¼ê°„", "M": "ì›”ê°„"}.get(freq, freq)

def _resample_close(df: pd.DataFrame, freq: str) -> pd.DataFrame:
    """
    df index must be DatetimeIndex, must have 'Close' column (or 1 col series)
    Returns DataFrame with Close resampled to period end.
    """
    if df is None or df.empty:
        return df

    if not isinstance(df.index, pd.DatetimeIndex):
        df = df.copy()
        df.index = pd.to_datetime(df.index)

    # If 'Close' not present, assume single column
    if "Close" not in df.columns:
        # pick first numeric col
        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        if not numeric_cols:
            return df
        df = df[[numeric_cols[0]]].rename(columns={numeric_cols[0]: "Close"})

    if freq == "D":
        return df[["Close"]].dropna()

    rule = "W-FRI" if freq == "W" else "M"
    out = df[["Close"]].resample(rule).last()
    return out.dropna()

def _metric_delta(series: pd.Series):
    series = series.dropna()
    if len(series) < 2:
        return None, None, None
    last = float(series.iloc[-1])
    prev = float(series.iloc[-2])
    delta = last - prev
    pct = (delta / prev) * 100 if prev != 0 else None
    return last, delta, pct

def _plot_line(df: pd.DataFrame, title: str, height: int = 260):
    if df is None or df.empty:
        st.info(f"{title}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if "Close" not in df.columns:
        # multi columns
        fig = go.Figure()
        for c in df.columns:
            fig.add_trace(go.Scatter(x=df.index, y=df[c], mode="lines", name=str(c)))
        fig.update_layout(title=title, height=height, margin=dict(l=10, r=10, t=40, b=10))
        st.plotly_chart(fig, use_container_width=True)
        return

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df.index, y=df["Close"], mode="lines", name="Close"))
    fig.update_layout(title=title, height=height, margin=dict(l=10, r=10, t=40, b=10))
    st.plotly_chart(fig, use_container_width=True)

def _safe_requests_get(url: str, timeout: int = 10, headers: dict | None = None):
    headers = headers or {
        "User-Agent": "Mozilla/5.0 (compatible; MISHARP-Dashboard/1.0; +https://streamlit.io)"
    }
    r = requests.get(url, timeout=timeout, headers=headers)
    r.raise_for_status()
    return r

def _normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    # í¼í¬ë¨¼ìŠ¤ ë¹„êµ(ê¸°ì¤€=100)
    out = df.copy()
    for c in out.columns:
        s = out[c].dropna()
        if len(s) == 0:
            continue
        out[c] = (out[c] / s.iloc[0]) * 100
    return out


# -----------------------------
# Data Fetchers (cached)
# -----------------------------
@st.cache_data(ttl=60 * 30)  # 30ë¶„
def fetch_fdr(symbol: str, start: str):
    df = fdr.DataReader(symbol, start)
    # FinanceDataReader: Close ì»¬ëŸ¼ ë³´ì¥(ëŒ€ë¶€ë¶„)
    if df is None or df.empty:
        return pd.DataFrame()
    df = df.copy()
    df.index = pd.to_datetime(df.index)
    return df

@st.cache_data(ttl=60 * 30)  # 30ë¶„
def fetch_yf(symbol: str, start: str):
    df = yf.download(symbol, start=start, progress=False, auto_adjust=False)
    if df is None or df.empty:
        return pd.DataFrame()
    df = df.copy()
    df.index = pd.to_datetime(df.index)
    return df

@st.cache_data(ttl=60 * 60)  # 1ì‹œê°„
def fetch_fred(series_list: list[str], start: datetime):
    # FREDëŠ” í‚¤ ì—†ì´ë„ pandas_datareaderë¡œ ë‹¤ìˆ˜ ì‹œë¦¬ì¦ˆ ì¡°íšŒ ê°€ëŠ¥
    df = DataReader(series_list, "fred", start)
    df.index = pd.to_datetime(df.index)
    return df

@st.cache_data(ttl=60 * 60)  # 1ì‹œê°„
def get_krx_top10_by_mktcap():
    # ê°€ì¥ ê°€ê¹Œìš´ ì˜ì—…ì¼(ì£¼) ê¸°ì¤€ ë‚ ì§œ ë¬¸ìì—´ yyyyMMdd
    biz = krx.get_nearest_business_day_in_a_week()
    caps = krx.get_market_cap_by_ticker(biz)
    # 'ì‹œê°€ì´ì•¡' ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
    caps = caps.sort_values("ì‹œê°€ì´ì•¡", ascending=False).head(10)
    # ì¢…ëª©ëª… ë¶™ì´ê¸°
    tickers = caps.index.tolist()
    names = [krx.get_market_ticker_name(t) for t in tickers]
    out = pd.DataFrame({
        "í‹°ì»¤": tickers,
        "ì¢…ëª©ëª…": names,
        "ì‹œê°€ì´ì•¡": caps["ì‹œê°€ì´ì•¡"].values
    })
    return biz, out

@st.cache_data(ttl=60 * 10)  # 10ë¶„
def fetch_rss(feed_url: str, limit: int = 20):
    d = feedparser.parse(feed_url)
    items = []
    for e in d.entries[:limit]:
        title = getattr(e, "title", "").strip()
        link = getattr(e, "link", "").strip()
        published = getattr(e, "published", "") or getattr(e, "updated", "")
        items.append({"title": title, "link": link, "published": published, "source": feed_url})
    return items

@st.cache_data(ttl=60 * 5)  # 5ë¶„
def fetch_naver_finance_news(limit: int = 20):
    # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤(ë©”ì¸) í˜ì´ì§€ë¥¼ ê°„ë‹¨ í¬ë¡¤ë§
    url = "https://finance.naver.com/news/"
    r = _safe_requests_get(url, timeout=10)
    soup = BeautifulSoup(r.text, "lxml")

    items = []
    # ì¹´ë“œ/ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ê°€ ì¢…ì¢… ë°”ë€Œë¯€ë¡œ, ê°€ì¥ í”í•œ aíƒœê·¸ íŒ¨í„´ì„ í­ë„“ê²Œ ìˆ˜ì§‘
    for a in soup.select("a"):
        href = a.get("href", "")
        text = a.get_text(" ", strip=True)
        if not text or len(text) < 8:
            continue
        # ë‰´ìŠ¤ ë§í¬ íŒ¨í„´(ìƒëŒ€/ì ˆëŒ€)
        if "news_read.naver" in href or "read.naver" in href or "news.naver.com" in href:
            link = href
            if link.startswith("/"):
                link = "https://finance.naver.com" + link
            items.append({"title": text, "link": link, "published": "", "source": "NAVER_FINANCE"})
        elif href.startswith("/news/") and "finance.naver.com" in url:
            link = "https://finance.naver.com" + href
            items.append({"title": text, "link": link, "published": "", "source": "NAVER_FINANCE"})

    # ì¤‘ë³µ ì œê±° + ìƒìœ„ limit
    seen = set()
    uniq = []
    for it in items:
        key = (it["title"], it["link"])
        if key in seen:
            continue
        seen.add(key)
        uniq.append(it)
        if len(uniq) >= limit:
            break
    return uniq


# -----------------------------
# Sidebar Controls
# -----------------------------
st.sidebar.header("âš™ï¸ ì„¤ì •")

auto_refresh = st.sidebar.toggle("ìë™ ìƒˆë¡œê³ ì¹¨(5ë¶„)", value=True)
news_limit = st.sidebar.slider("ë‰´ìŠ¤ í‘œì‹œ ê°œìˆ˜", 10, 50, 20, 5)
show_brent = st.sidebar.toggle("ìœ ê°€: ë¸Œë ŒíŠ¸(BZ=F)ë„ í‘œì‹œ", value=True)

if auto_refresh:
    # Streamlit ë°©ì‹ì˜ ì£¼ê¸°ì  rerun
    st.sidebar.caption("ìë™ ìƒˆë¡œê³ ì¹¨: 5ë¶„ë§ˆë‹¤ ê°±ì‹ ")
    time.sleep(0.01)
    st.cache_data.clear()
    st.rerun()


# -----------------------------
# Main Rendering
# -----------------------------
def render_tab(freq: str):
    days = _days_for_freq(freq)
    start_dt = _today_kst() - timedelta(days=days)
    start = start_dt.strftime("%Y-%m-%d")

    # 1) ì£¼ìš” ì§€ìˆ˜
    st.subheader("1) ì£¼ìš” ì£¼ê°€ì§€ìˆ˜")
    c1, c2, c3 = st.columns(3)

    with c1:
        df_ks11 = fetch_fdr("KS11", start)
        df_ks11 = _resample_close(df_ks11, freq)
        last, delta, pct = _metric_delta(df_ks11["Close"]) if not df_ks11.empty else (None, None, None)
        st.metric("KOSPI (KS11)", f"{last:,.2f}" if last is not None else "-", f"{delta:,.2f} ({pct:+.2f}%)" if pct is not None else None)
        _plot_line(df_ks11, "KOSPI")

    with c2:
        df_kq11 = fetch_fdr("KQ11", start)
        df_kq11 = _resample_close(df_kq11, freq)
        last, delta, pct = _metric_delta(df_kq11["Close"]) if not df_kq11.empty else (None, None, None)
        st.metric("KOSDAQ (KQ11)", f"{last:,.2f}" if last is not None else "-", f"{delta:,.2f} ({pct:+.2f}%)" if pct is not None else None)
        _plot_line(df_kq11, "KOSDAQ")

    with c3:
        sp = _resample_close(fetch_yf("^GSPC", start), freq)
        nas = _resample_close(fetch_yf("^IXIC", start), freq)
        dow = _resample_close(fetch_yf("^DJI", start), freq)

        # í•©ì³ì„œ í•˜ë‚˜ì˜ ë¹„êµ ê·¸ë˜í”„
        df_us = pd.DataFrame({
            "S&P500": sp["Close"] if not sp.empty else pd.Series(dtype=float),
            "NASDAQ": nas["Close"] if not nas.empty else pd.Series(dtype=float),
            "DOW": dow["Close"] if not dow.empty else pd.Series(dtype=float),
        }).dropna(how="all")

        st.caption("ë¯¸êµ­ ì§€ìˆ˜ ë¹„êµ")
        _plot_line(_normalize_cols(df_us.dropna()), "US Indices (Normalized=100)", height=260)

    st.divider()

    # 2) êµ­ë‚´ ì‹œì´ Top10
    st.subheader("2) êµ­ë‚´ ì‹œê°€ì´ì•¡ Top10 (ìë™ ì¶”ì¶œ)")
    biz, top10 = get_krx_top10_by_mktcap()
    st.caption(f"ê¸°ì¤€ ì˜ì—…ì¼: {biz}")

    # Top10 ê°€ê²© ë°ì´í„°
    tickers = top10["í‹°ì»¤"].tolist()
    names = top10["ì¢…ëª©ëª…"].tolist()

    prices = {}
    for t, n in zip(tickers, names):
        try:
            dft = fetch_fdr(t, start)
            dft = _resample_close(dft, freq)
            if not dft.empty:
                prices[n] = dft["Close"]
        except Exception:
            continue

    df_top = pd.DataFrame(prices).dropna(how="all")
    c1, c2 = st.columns([1, 2])
    with c1:
        st.dataframe(top10, use_container_width=True, hide_index=True)
    with c2:
        if not df_top.empty:
            _plot_line(_normalize_cols(df_top.dropna()), "KRX Top10 (Normalized=100)", height=300)
        else:
            st.info("Top10 ê°€ê²© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.divider()

    # 3) í™˜ìœ¨
    st.subheader("3) í™˜ìœ¨ (USD/KRW)")
    df_fx = fetch_fdr("USD/KRW", start)
    df_fx = _resample_close(df_fx.rename(columns={"Close": "Close"}), freq) if "Close" in df_fx.columns else _resample_close(df_fx, freq)
    if df_fx.empty and "Close" not in df_fx.columns:
        # FDR í™˜ìœ¨ì€ ë³´í†µ 'Close' ëŒ€ì‹  ë‹¨ì¼ ì»¬ëŸ¼ì¼ ìˆ˜ë„ ìˆì–´ ì²˜ë¦¬
        df_fx = _resample_close(df_fx, freq)

    if not df_fx.empty:
        last, delta, pct = _metric_delta(df_fx["Close"])
        st.metric("ì›/ë‹¬ëŸ¬", f"{last:,.2f}", f"{delta:,.2f} ({pct:+.2f}%)")
    _plot_line(df_fx, "USD/KRW")

    st.divider()

    # 4) ê¸ˆ ì‹œì„¸
    st.subheader("4) ê¸ˆ ì‹œì„¸ (Gold Futures: GC=F)")
    df_gold = _resample_close(fetch_yf("GC=F", start), freq)
    if not df_gold.empty:
        last, delta, pct = _metric_delta(df_gold["Close"])
        st.metric("Gold (GC=F)", f"{last:,.2f}", f"{delta:,.2f} ({pct:+.2f}%)")
    _plot_line(df_gold, "Gold (GC=F)")

    st.divider()

    # 5) ìœ ê°€
    st.subheader("5) ìœ ê°€ (WTI / Brent)")
    wti = _resample_close(fetch_yf("CL=F", start), freq)
    brent = _resample_close(fetch_yf("BZ=F", start), freq) if show_brent else pd.DataFrame()

    c1, c2 = st.columns(2)
    with c1:
        if not wti.empty:
            last, delta, pct = _metric_delta(wti["Close"])
            st.metric("WTI (CL=F)", f"{last:,.2f}", f"{delta:,.2f} ({pct:+.2f}%)")
        _plot_line(wti, "WTI (CL=F)")
    with c2:
        if show_brent:
            if not brent.empty:
                last, delta, pct = _metric_delta(brent["Close"])
                st.metric("Brent (BZ=F)", f"{last:,.2f}", f"{delta:,.2f} ({pct:+.2f}%)")
            _plot_line(brent, "Brent (BZ=F)")
        else:
            st.info("ì‚¬ì´ë“œë°”ì—ì„œ Brent í‘œì‹œë¥¼ ì¼¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.divider()

    # 6) ê¸ˆë¦¬ ë™í–¥
    st.subheader("6) ê¸ˆë¦¬ ë™í–¥ (ë¯¸êµ­/êµ­ë‚´)")
    fred = fetch_fred(
        ["DGS10", "FEDFUNDS", "IRLTLT01KRM156N"],  # US 10Y, Fed Funds, KR 10Y(OECD via FRED)
        start_dt
    )
    if fred is None or fred.empty:
        st.info("ê¸ˆë¦¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        # resample
        if freq == "W":
            fred_r = fred.resample("W-FRI").last()
        elif freq == "M":
            fred_r = fred.resample("M").last()
        else:
            fred_r = fred.copy()

        c1, c2, c3 = st.columns(3)
        with c1:
            s = fred_r["DGS10"].dropna()
            if len(s) >= 2:
                st.metric("ë¯¸êµ­ 10Y (DGS10)", f"{s.iloc[-1]:.2f}%", f"{(s.iloc[-1]-s.iloc[-2]):+.2f}p")
            _plot_line(pd.DataFrame({"Close": fred_r["DGS10"]}).dropna(), "US 10Y (DGS10)")
        with c2:
            s = fred_r["FEDFUNDS"].dropna()
            if len(s) >= 2:
                st.metric("ë¯¸êµ­ ê¸°ì¤€ê¸ˆë¦¬(FedFunds)", f"{s.iloc[-1]:.2f}%", f"{(s.iloc[-1]-s.iloc[-2]):+.2f}p")
            _plot_line(pd.DataFrame({"Close": fred_r["FEDFUNDS"]}).dropna(), "Fed Funds Rate")
        with c3:
            s = fred_r["IRLTLT01KRM156N"].dropna()
            if len(s) >= 2:
                st.metric("í•œêµ­ 10Y (FRED/OECD)", f"{s.iloc[-1]:.2f}%", f"{(s.iloc[-1]-s.iloc[-2]):+.2f}p")
            _plot_line(pd.DataFrame({"Close": fred_r["IRLTLT01KRM156N"]}).dropna(), "Korea 10Y (IRLTLT01KRM156N)")

    st.divider()

    # 7) ì‹¤ì‹œê°„ ê²½ì œë‰´ìŠ¤
    st.subheader("7) ì‹¤ì‹œê°„ ê²½ì œ ë‰´ìŠ¤ (ë„¤ì´ë²„/ë‹¤ìŒ/êµ¬ê¸€)")
    st.caption("ë„¤ì´ë²„ëŠ” ê³µì‹ RSSê°€ ì œí•œì ì´ë¼ ê¸ˆìœµ ë‰´ìŠ¤ í˜ì´ì§€ í¬ë¡¤ë§, ë‹¤ìŒ/êµ¬ê¸€ì€ RSS ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")

    daum_rss = "http://media.daum.net/rss/part/primary/economic/rss2.xml"
    google_rss = "http://news.google.co.kr/news?pz=1&hdlOnly=1&cf=all&ned=kr&hl=ko&topic=b&output=rss"

    colA, colB, colC = st.columns(3)
    with colA:
        st.markdown("**NAVER (Finance)**")
        try:
            items = fetch_naver_finance_news(limit=news_limit)
            for it in items:
                st.markdown(f"- [{it['title']}]({it['link']})")
        except Exception as e:
            st.warning(f"ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    with colB:
        st.markdown("**DAUM (RSS)**")
        try:
            items = fetch_rss(daum_rss, limit=news_limit)
            for it in items:
                title = it["title"]
                link = it["link"]
                pub = it["published"]
                pub_txt = f" Â· {pub}" if pub else ""
                st.markdown(f"- [{title}]({link}){pub_txt}")
        except Exception as e:
            st.warning(f"ë‹¤ìŒ RSS ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    with colC:
        st.markdown("**GOOGLE NEWS (RSS)**")
        try:
            items = fetch_rss(google_rss, limit=news_limit)
            for it in items:
                title = it["title"]
                link = it["link"]
                pub = it["published"]
                pub_txt = f" Â· {pub}" if pub else ""
                st.markdown(f"- [{title}]({link}){pub_txt}")
        except Exception as e:
            st.warning(f"êµ¬ê¸€ RSS ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")


tabs = st.tabs(["ì¼ê°„", "ì£¼ê°„", "ì›”ê°„"])
with tabs[0]:
    render_tab("D")
with tabs[1]:
    render_tab("W")
with tabs[2]:
    render_tab("M")

st.caption("Tip) Streamlit Cloud ë¬´ë£Œ í”Œëœì€ ì™¸ë¶€ ìš”ì²­ì´ ê°„í—ì ìœ¼ë¡œ ë§‰í ìˆ˜ ìˆì–´ìš”. ê·¸ëŸ´ ë• ìºì‹œ TTLì„ ëŠ˜ë¦¬ê±°ë‚˜(30ë¶„â†’1ì‹œê°„) ë‰´ìŠ¤ë§Œ ìˆ˜ë™ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ìš´ì˜í•˜ë©´ ì•ˆì •ì ì…ë‹ˆë‹¤.")
